---
title: eureka集群
tags:

  - SpringCloud
---

### eureka集群

#### eureka集群原理

服务启动后向eureka注册，eureka server 会将注册信息向其他 eureka server进行同步，当服务系哦啊覆辙要调用服务提供者，则向服务注册中心获取服务提供者地址，然后会将服务提供者地址缓存在本地，直接从本地缓存中取，完成一次调用。

#### eureka集群配置

我们知道eureka server会将注册信息向其他eureka server进行同步，那么我们如何配置呢？

这里我们新建三个Eureka server服务端：

![image-20201027135345288](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027135345288.png)



![image-20201027135433543](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027135433543.png)

我们具体来看如何配置呢？

```yml
server:
  port: 3003
eureka:
  server:
    enable-self-preservation: false
    eviction-interval-timer-in-ms: 4000
  instance:
    hostname: eureka3003.com

  client:
    register-with-eureka: false
    fetch-registry: false
    serviceUrl:
      defaultZone: http://eureka3001.com:3001/eureka,http://eureka3002.com:3002/eureka

```

因为在本地host文件进行域名映射一下：

`‪C:\Windows\System32\drivers\etc\hosts`

```
127.0.0.1 eureka3001.com
127.0.0.1 eureka3002.com
127.0.0.1 eureka3003.com
```

我们发现集群配置与单体配置的不同点在于，原来是把服务注册到自己身上，现在是注册到其他服务身上。

启动三个服务端后，我们可以看到我们eureka集群已经可以访问了。

![image-20201027141638045](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027141638045.png)



接下来我们配置客户端：(我新建一个user模块)

```java
server:
  port: 8000
eureka:
  client:
    service-url:
      defaultZone: http://eureka3001.com:3001/eureka,http://eureka3002.com:3002/eureka,http://eureka3003.com:3003/eureka
  instance:
    instance-id: user-1 #此实例注册到eureka服务端的唯一实例ID
    prefer-ip-address: true #是否显示IP地址
    lease-renewal-interval-in-seconds: 10 #eureka客户端需要多长时间发送心跳给eureka服务器，表名它仍然活着，默认为30秒（与下面配置的单位都是秒）
spring:
  application:
    name: user-server  #此实例注册到eureka服务端的name
```

![image-20201027144946956](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027144946956.png)

可以看到，我们的user服务已经注册到eureka集群了。



### CAP定理

![image-20201027154247509](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027154247509.png)

分布式系统的三个指标：

```
Consistency				----一致性
Availability			----可用性
Partition tolerance		分区容错性
```

这灿哥指标不能同时做到，这个结论就叫做CAP定理。

#### Partition tolerance

即分区容错。

大多数分布式系统都分布在多个子网络。每个子网络叫做一个区（partition）。

分区容错的意思就是，区间通信可能失败，比如一台服务器在本地，另一台服务器放在外电，这流失两个区，之间可能无法通信。

![image-20201027154842591](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027154842591.png)

上图中，S1和S2是两台跨区的服务器。S1向S2发送一条消息，S2可能无法收到。系统设计的时候必须考虑到这种情况。

一般来说，分区容错无法避免，因此可以认为CAP的P总是成立。**CAP定理告诉我们，剩下的C和A无法同时做到。**



#### Consistency

一致性，意思是，写操作之后的读操作，必须返回该写的值。

比如，某条记录是v0，用户想S1发起一个写操作，将其改为v1。接下来用户读操作就会得到v1，这就叫一致性。

![image-20201027155517624](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027155517624.png)

问题是，用户有可能向S2发起读操作，由于S2的值没有发生变化，因此返回v0，所以S1和S2的读操作不一致，这就不满足一致性了。



为了让S2的返回值与S1一致，所以我们需要在往S1执行写操作的时候，让S1给S2也发送一条消息，要求S2也变成V1。

![image-20201027155901661](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027155901661.png)



#### Availability

可用性，意思是只要收到用户的请求，服务器就必须给出回应。

用户可以选择向S1 或 S2发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是v0还是v1。



#### Consistency 和 Availability 的矛盾

一致性和可用性，为什么不能同时成立？ 因为可能通信失败（即出现分区容错）。

如果保证S2的一致性，那么S1必须在写操作时，锁定S2的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，S2不能读写，没有可用性。

如果保证S2的可用性，那么势必不能锁定S2，所以一致性不成立。

我们设计系统时只能选择一个目标。



### eureka与zookeeper对比

zookeeper在设计的时候遵循的是CP原则，即一致性。Zookeeper会出现这样一种情况，当master结点因为网络故障与其它节点失去联系时剩余节点会重新进行leader选举，问题在于，选举leader的时间太长：30~120s，且选举期间整个zk集群是不可用的，这就导致在选举期间注册服务处于瘫痪状态，在云部署的环境下，因网络环境使zk集群失去master节点是较大概率的事情，虽然服务能够最终恢复，但是漫长的选举时间导致长期的服务注册不可用是不能容忍的。



Eureka在设计的时候遵循的是AP原则，即可见性。Eureka各个节点（服务）都是平等的，没有主从之分，几个节点down掉不会影响正常工作，剩余的结点（服务）依然可以提供注册与查询服务，而Eureka的客户端向某个Eureka server注册或发现连接失败，则会自动切换到其他结点，也就是说，只要有一台Eureka还在，就可以注册查找服务（可用性），只不过查询到的信息不是最新的（不保证强一致）。

除此之外，Eureka还有自我保护机制，如果在15分钟内超过85%节点都没有正常心跳，那么eureka就会认为客户端与注册中心出现了网络故障，此时会出现以下情况：

1. Eureka 不再从注册列表中移除因为长时间没有收到心跳的服务。
2. Eureka 仍然能够接收新服务的注册和查询请求，但是不会被同步到其他节点上（即保证当前节点可用）。
3. 当网络稳定后，当前实例新的注册信息会被同步到其他结点中。



