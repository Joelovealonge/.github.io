---
 title: hystrix
tags:

  - SpringCloud
---

### hystrix

#### hystrix 断路器是什么？

hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，**Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。**

“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似于熔断保险丝），想调用方返回一个符合预期、可处理的备选响应，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在风不是系统中的蔓延，乃至雪崩。



#### 大型项目中可能出现的问题：

![image-20201027205216906](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027205216906.png)

上图是一条微服务的调用链，假设现在微服务H响应时间过长，或者微服务H之间down机了如图：

![image-20201027205355567](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201027205355567.png)

如果发生这种情况，也就是说所有发给微服务D的请求，都会被卡在微服务H那儿，就会导致线程一直累计在这里，那么其他的微服务（比如A，B，C...）就没有可用线程了，导致整个服务器崩溃，这就是服务雪崩。

导致服务雪崩的情况：

程序BUG，数据不匹配，响应时间过长，服务不可用等等

针对上面的问题，我们看有哪些解决方案：

- 服务限流

- 超时监控

- 服务熔断

- 服务降级



#### 降级，超时

降级就是当我们的某个微服务响应时间过长，或者不可以了，说白了就是**哪个微服务掉用不了了，我们不能把错误信息返回出来，或者让他一直卡在那里，所以要再准备一个对应的策略（方法），当发送这种问题的时候直接调用这个方法来快速返回这个请求**，不让他一直卡在那。



那么哪个微服务需要做降级处理呢？

要在调用方做降级（不然哪个微服务都down掉了在做降级也没意义），比如我们的user调用power那么就在user做降级。

下面来看具体实现：

user模块引入hystrix依赖：

```xml
        <!--hystrix-->
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
        </dependency>
```

启动类加入注解`@EnableHstrix`或者`@EnableCircuitBreaker`（他们之间是一个继承关系）, 2个注解锁描述的内容时完全一样的，

然后我们在我们controller上面加入注解`@HystrixCommand`(fallbackMethod就是我们的备用逻辑即方法)

```java
@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
@EnableHystrix
public class AppUser {
    public static void main(String[] args) {
        SpringApplication.run(AppUser.class);
    }
}
```

```java
@Controller
public class UserController {

    @Autowired
    PowerServerClient powerServerClient;

    @RequestMapping("/getUser")
    @ResponseBody
    @HystrixCommand(fallbackMethod = "getPowerFallbackMethod")
    public R getUser() {
        String msg = "getUser接口->" ;
        return R.success(msg,powerServerClient.getPower());
    }

    public R getPowerFallbackMethod() {
        return R.error("降级信息");
    }
}
```

这个降级信息具体内容得根据也无需求来，比如返回一个默认的查询信息，亦或是系统维护（因为有可能要暂时关闭某个微服务而把资源让给其他服务）等等

我们在power1代码里模拟一个异常

```java
@Controller
public class PowerController {

    @RequestMapping("/getPower")
    @ResponseBody
    public R getPower(String msg, String userId) throws Exception {
        msg+="====power1";
        if (userId == null){
            throw new Exception();
        }
        return R.success(msg);
    }
```

看一下结果：

![image-20201028090536656](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201028090536656.png)

我们将power2中的代码改动一下，让她故意等待一会儿（模拟响应超时）

```java
@Controller
public class PowerController {

    @RequestMapping("/getPower")
    @ResponseBody
    public R getPower(String msg) throws InterruptedException {
        msg+="====power2";
        Thread.sleep(4000);
        return R.success(msg);
    }
}
```

![image-20201028091310189](https://cdn.jsdelivr.net/gh/joelovealonge/noteimgs/image-20201028091310189.png)

不知道大家有没有疑问，如何知道超时？也就是说多久算超时？

hystrix有默认的超时监听，当你这个请求超过了一秒就会超时，当然这个是可以配置的。详见本文最后。



**降级的作用：**

	1. 她可以监听你的请求有没有超时
 	2. 报错了她这里直接截断了没有让请求一直卡在这里。
 	3. 整体资源不够了，比如双十一秒杀这种高并发，可以考虑关掉一些不重要的服务，在降级方法中返回一个比较友好的信息，把资源让给主微服务，待读过难关，在重启回来。



#### 熔断，限流

**熔断：**

就像跳闸一样，当一个微服务调用多次出现问题时（默认10秒内20次，当然可以配置），hstrix就会采取熔断机制，不在继续调用你的方法（会在默认5秒钟内核电器短路一样，5秒钟后会试探性关闭熔断机制，但是如果这时候再失败一次｛之前是2次｝），而是直接调用降级方法，这样就一定程度上避免了服务雪崩的问题。



**限流：**

顾名思义，就是限制你某个微服务的使用量（可用线程）

hystrix通过线程池的方式来管理你的微服务调用，她默认是一个线程池（10大小）管理你的所有微服务，你可以给某个微服务开辟新的线程池：

```java
@Controller
public class UserController {

    @Autowired
    PowerServerClient powerServerClient;

    @RequestMapping("/getUserLimit")
    @ResponseBody
    @HystrixCommand(fallbackMethod = "getPowerFallbackMethod", 
                    threadPoolKey = "order",
                    threadPoolProperties = {@HystrixProperty(name = "coreSize", value = "2"),
                                            @HystrixProperty(name="maxQueueSize", value = "1")})
    public R getUserLimit() {
        String msg = "getUser接口->" + powerServerClient.getPower();
        return R.success(msg);
    }

    public R getPowerFallbackMethod() {
        return R.error("超时后降级信息");
    }
}
```

threadPoolKey就是线程池唯一标识，hystrix会拿你这个表示去计数，看线程池占用是否超过了，超过了就会直接降级该次调用

比如，这里的coreSize给他值为2，那么假设你这个方法调用时间是3s执行完，那么在3秒内如果有超过2个请求进来的话，剩下的请求则全部降级。



#### feign整合hystix

feign默认是支持hystrix的，但是在spring-cloud Dalston版本之后就默认关闭了，因为不一定业务需求要用到，

我们打开她，在yml文件加上如下配置：

```yaml
feign:
  hystrix:
    enabled: true
```

加上配置后降级方法如何写呢？

```java
@FeignClient(value = "power-server", fallback = PowerServerFallBack.class)
public interface PowerServerClient1 {
    @RequestMapping("/getPower")
    public Object getPower();
}
```

```java
@Component
public class PowerServerFallBack implements  PowerServerClient1{
    @Override
    public R getPower() {
        return R.error("测试降级");
    }
}
```

```java
@Controller
public class UserController {
    @Autowired
    PowerServerClient1 powerServerClient1;

    @RequestMapping("/getUserFeignAndHystix")
    @ResponseBody
    public R getUserFeignAndHystix() {
        String msg = "getUser接口->" + powerServerClient1.getPower();
        return R.success(msg);
    }
```



当然也可能有这种需求，需要拿到具体的错误信息，那么可以这样写：

```java
@Component
public class PowerServerClientFallBackFactory implements FallbackFactory<PowerServerClient1> {
    @Override
    public PowerServerClient1 create(Throwable throwable) {
        return new PowerServerClient1() {
            @Override
            public Object getPower() {
                String message = throwable.getMessage();
                return R.error("feign降级"+ message);
            }
        };
    }
}
```

客服端指定一个fallbackFactory就好了

```java
@FeignClient(value = "power-server", fallbackFactory = PowerServerClientFallBackFactory.class)
public interface PowerServerClient1 {
    @RequestMapping("/getPower")
    public Object getPower();
}
```



#### hystrix相关配置

```yaml
Execution相关的属性的配置
hystrix.command.default.execution.isolation.strategy 隔离策略，默认是Thread, 可选Thread｜ Semaphor

hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 命令执行超时时 间，默认1000ms

hystrix.command.default.execution.timeout.enabled 执行是否启用超时，默认启用true

hystrix.command.default.execution.isolation.thread.interruptOnTimeout 发生超时是是否中断， 默认true

hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 最大并发请求 数，默认10，该参数当使用ExecutionIsolationStrategy.SEMAPHORE策略时才有效。如果达到最大并发请求 数，请求会被拒绝。理论上选择semaphore size的原则和选择thread size一致，但选用semaphore时每次执行 的单元要比较小且执行速度快（ms级别），否则的话应该用thread。 semaphore应该占整个容器（tomcat）的线程池的一小部分。 Fallback相关的属性 这些参数可以应用于Hystrix的THREAD和SEMAPHORE策略

hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests 如果并发数达到 该设置值，请求会被拒绝和抛出异常并且fallback不会被调用。默认10

hystrix.command.default.fallback.enabled 当执行失败或者请求被拒绝，是否会尝试调用

hystrixCommand.getFallback() 。默认true

Circuit Breaker相关的属性 
hystrix.command.default.circuitBreaker.enabled 用来跟踪circuit的健康性，如果未达标则让request短路。默认true

hystrix.command.default.circuitBreaker.requestVolumeThreshold 一个rolling window内最小的请 求数。如果设为20，那么当一个rolling window的时间内（比如说1个rolling window是10秒）收到19个请求， 即使19个请求都失败，也不会触发circuit break。默认20

hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds 触发短路的时间值，当该值设 为5000时，则当触发circuit break后的5000毫秒内都会拒绝request，也就是5000毫秒后才会关闭circuit。 默认5000

hystrix.command.default.circuitBreaker.errorThresholdPercentage错误比率阀值，如果错误率>=该 值，circuit会被打开，并短路所有请求触发fallback。默认50

hystrix.command.default.circuitBreaker.forceOpen 强制打开熔断器，如果打开这个开关，那么拒绝所 有request，默认false

hystrix.command.default.circuitBreaker.forceClosed 强制关闭熔断器 如果这个开关打开，circuit将 一直关闭且忽略circuitBreaker.errorThresholdPercentage

Metrics相关参数

hystrix.command.default.metrics.rollingStats.timeInMilliseconds 设置统计的时间窗口值的，毫秒 值，circuit break 的打开会根据1个rolling window的统计来计算。若rolling window被设为10000毫秒， 则rolling window会被分成n个buckets，每个bucket包含success，failure，timeout，rejection的次数 的统计信息。默认10000

hystrix.command.default.metrics.rollingStats.numBuckets 设置一个rolling window被划分的数 量，若numBuckets＝10，rolling window＝10000，那么一个bucket的时间即1秒。必须符合rolling window  % numberBuckets == 0。默认10

hystrix.command.default.metrics.rollingPercentile.enabled 执行时是否enable指标的计算和跟踪， 默认true

hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 设置rolling  percentile window的时间，默认60000

hystrix.command.default.metrics.rollingPercentile.numBuckets 设置rolling percentile  window的numberBuckets。逻辑同上。默认6

hystrix.command.default.metrics.rollingPercentile.bucketSize 如果bucket size＝100，window ＝10s，若这10s里有500次执行，只有最后100次执行会被统计到bucket里去。增加该值会增加内存开销以及排序 的开销。默认100

hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 记录health 快照（用 来统计成功和错误绿）的间隔，默认500ms


Request Context 相关参数

hystrix.command.default.requestCache.enabled 默认true，需要重载getCacheKey()，返回null时不 缓存

 hystrix.command.default.requestLog.enabled 记录日志到HystrixRequestLog，默认true
 
 Collapser Properties 相关参数
 
 hystrix.collapser.default.maxRequestsInBatch 单次批处理的最大请求数，达到该数量触发批处理，默认 Integer.MAX_VALU
 
 hystrix.collapser.default.timerDelayInMilliseconds 触发批处理的延迟，也可以为创建批处理的时间 ＋该值，默认10
 
 hystrix.collapser.default.requestCache.enabled 是否对HystrixCollapser.execute() and  HystrixCollapser.queue()的cache，默认true
 
 ThreadPool 相关参数
 
 线程数默认值10适用于大部分情况（有时可以设置得更小），如果需要设置得更大，那有个基本得公式可以 follow： requests per second at peak when healthy × 99th percentile latency in seconds + some  breathing room 每秒最大支撑的请求数 (99%平均响应时间 + 缓存值) 比如：每秒能处理1000个请求，99%的请求响应时间是60ms，那么公式是： 1000 （0.060+0.012）
 
 基本得原则时保持线程池尽可能小，他主要是为了释放压力，防止资源被阻塞。 当一切都是正常的时候，线程池一般仅会有1到2个线程激活来提供服务
 
 hystrix.threadpool.default.coreSize 并发执行的最大线程数，默认10
 
 hystrix.threadpool.default.maxQueueSize BlockingQueue的最大队列数，当设为－1，会使用
 
 SynchronousQueue，值为正时使用LinkedBlcokingQueue。该设置只会在初始化时有效，之后不能修改threadpool的queue size，除非reinitialising thread executor。默认－1。
 
 hystrix.threadpool.default.queueSizeRejectionThreshold 即使maxQueueSize没有达到，达到 queueSizeRejectionThreshold该值后，请求也会被拒绝。因为maxQueueSize不能被动态修改，这个参数将允 许我们动态设置该值。if maxQueueSize == ¬1，该字段将不起作用 hystrix.threadpool.default.keepAliveTimeMinutes 如果corePoolSize和maxPoolSize设成一样（默认 实现）该设置无效。如果通过plugin（https://github.com/Netflix/Hystrix/wiki/Plugins）使用自定义 实现，该设置才有用，默认1.
 hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds 线程池统计指标的时间，默 认10000
 
 hystrix.threadpool.default.metrics.rollingStats.numBuckets 将rolling window划分为n个 buckets，默认10

```

